{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1. 토큰화.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNk2PmqwxLoE2SL6AKWBvkF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **토큰화(Tokenization)**  \n","주어진 코퍼스(corpus)에서 토큰(token)이라 불리는 단위로 나누는 작어을 토큰화라고 한다.  \n","토큰의 단위가 상황에 따라 다르지만, 보통 의미있는 단위로 토큰을 정의한다."],"metadata":{"id":"o1-L8jeTxzHi"}},{"cell_type":"markdown","source":["### **단어 토큰화**  \n","토큰의 기준을 단어(word)로 하는 경우  \n","단어는 단어 단위 외에도 단어구, 의미를 갖는 문자열로도 간주되기도 한다.  \n","보통 토큰화 작업은 단순히 구두점이나 특수문자를 전부 제거하는 정제(cleaning) 작업을 수행하는 것만으로 해결되지 않는다. 구두점이나 특수문자를 전부 제거하면 토큰이 의미를 잃어버리는 경우가 발생하기도 한다."],"metadata":{"id":"jWsgz-2fxvOO"}},{"cell_type":"markdown","source":["**토큰화 중 생기는 선택의 순간**  \n","예) 아포스트로피(')가 들어가있는 단어 구분"],"metadata":{"id":"1T0AzSVkxrcO"}},{"cell_type":"markdown","source":["NLTK : 영어 코퍼스를 토큰화하기 위한 도구들을 제공"],"metadata":{"id":"kcix1QWTVKtW"}},{"cell_type":"markdown","source":["**1. word_tokenize**"],"metadata":{"id":"DOc07P1TVlNK"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","print(\"단어 토큰화1 :\", word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IvFU19zrVSXm","executionInfo":{"status":"ok","timestamp":1652863564355,"user_tz":-540,"elapsed":784,"user":{"displayName":"남희정","userId":"05541235909914296292"}},"outputId":"b937245d-38e2-4e46-ea85-b356ee5f69ac"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","단어 토큰화1 : ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"]}]},{"cell_type":"markdown","source":["**2. wordPunctTokenizer**"],"metadata":{"id":"-oHDMmglVwtD"}},{"cell_type":"code","source":["from nltk.tokenize import WordPunctTokenizer\n","print(\"단어 토큰화2 : \", WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8RU8Vk3Vkho","executionInfo":{"status":"ok","timestamp":1652863639825,"user_tz":-540,"elapsed":296,"user":{"displayName":"남희정","userId":"05541235909914296292"}},"outputId":"47678c49-5935-4d35-c48a-827ba17778e1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 토큰화2 :  ['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"]}]},{"cell_type":"markdown","source":["**3. text_to_word_sequence**"],"metadata":{"id":"YZ6I38tIWMy5"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import text_to_word_sequence\n","\n","print(\"단어 토큰화3 : \", text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S2xVAal1WMgW","executionInfo":{"status":"ok","timestamp":1652863676548,"user_tz":-540,"elapsed":3314,"user":{"displayName":"남희정","userId":"05541235909914296292"}},"outputId":"f57c3892-0b31-4aad-eef5-d08ae650ee94"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 토큰화3 :  [\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"]}]},{"cell_type":"markdown","source":["### **토큰화에서 고려해야할 사항**  \n","1. 구두점이나 특수 문자를 단순 제외해서는 안된다.\n","2. 줄임말과 단어 내에 띄어쓰기가 있는 경우\n","3. 표준 토큰화(Peen Treebank Tokenization)\n","    - 하이푼으로 구성된 단어는 하나로 유지한다.\n","    - doesn't와 같이 아포스트로피로 '접어'가 함께하는 단어는 분리해준다."],"metadata":{"id":"mKkWyTXlWk0d"}},{"cell_type":"code","source":["from nltk.tokenize import TreebankWordTokenizer\n","\n","tokenizer = TreebankWordTokenizer()\n","\n","text = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n","print(\"트리뱅크 워드토크나이저 : \", tokenizer.tokenize(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jGlGHuxbWiEN","executionInfo":{"status":"ok","timestamp":1652863906554,"user_tz":-540,"elapsed":15,"user":{"displayName":"남희정","userId":"05541235909914296292"}},"outputId":"151626ce-a9aa-4e85-e5d2-f51e97f2d624"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["트리뱅크 워드토크나이저 :  ['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"]}]},{"cell_type":"markdown","source":["# **문장 토큰화**  \n","코퍼스 내에서 문장 단위로 구분하는 작업으로 때로는 문장 분류라고도 부른다.  \n","보통 갖고 있는 코퍼스가 정제되지 않은 상태라면, 코퍼스는 문장 단위로 구분되어 있지 않아서 이를 사용하고자 하는 용도에 맞게 문장 토큰화가 필요할 수 있다."],"metadata":{"id":"87CHuFXcXdBS"}},{"cell_type":"markdown","source":["NLTK에서는 영어 문장의 토큰화를 수행하는 sent_tokenize를 지원하고 있다."],"metadata":{"id":"JWjmvL2UXa8P"}},{"cell_type":"code","source":["from nltk.tokenize import sent_tokenize\n","\n","text = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n","print(\"문장 토큰화1 :\", sent_tokenize(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EfXNGs4TX-G5","executionInfo":{"status":"ok","timestamp":1652864093710,"user_tz":-540,"elapsed":334,"user":{"displayName":"남희정","userId":"05541235909914296292"}},"outputId":"d42b493a-2149-44a2-9e0e-cc40acce7a1b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["문장 토큰화1 : ['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n"]}]},{"cell_type":"code","source":["text2 = \"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\n","print('문장 토큰화2 :',sent_tokenize(text2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKp_PzlOYItB","executionInfo":{"status":"ok","timestamp":1652864118715,"user_tz":-540,"elapsed":361,"user":{"displayName":"남희정","userId":"05541235909914296292"}},"outputId":"56d0b925-e82e-4ade-9b5e-d2469b5e487f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["문장 토큰화2 : ['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"]}]},{"cell_type":"markdown","source":["한국어에 대한 문장 토큰화 도구 ==> KSS(Korean Sentence Splitter)"],"metadata":{"id":"2jQ2O-SFYUIZ"}},{"cell_type":"code","source":["!pip install kss\n","import kss\n","\n","text3 = '딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?'\n","print('한국어 문장 토큰화 :',kss.split_sentences(text3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JFTs4YArYarQ","executionInfo":{"status":"ok","timestamp":1652864234640,"user_tz":-540,"elapsed":26871,"user":{"displayName":"남희정","userId":"05541235909914296292"}},"outputId":"32a7e36f-5d86-46fb-c169-658d1dfe8265"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kss\n","  Downloading kss-3.4.2.tar.gz (42.4 MB)\n","\u001b[K     |████████████████████████████████| 42.4 MB 880 kB/s \n","\u001b[?25hCollecting emoji\n","  Downloading emoji-1.7.0.tar.gz (175 kB)\n","\u001b[K     |████████████████████████████████| 175 kB 36.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from kss) (2019.12.20)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.7/dist-packages (from kss) (8.13.0)\n","Building wheels for collected packages: kss, emoji\n","  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kss: filename=kss-3.4.2-py3-none-any.whl size=42448069 sha256=50d3c15304e316f98a3e36878fa3b94cbc885a28b3b2ff1250a42fc5b2862bdc\n","  Stored in directory: /root/.cache/pip/wheels/ef/22/aa/6399b60516a067ec97fa6599fb2d472aeb25e3f9ee6dae3224\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=5fe3f7fbfcc37794cb363da41d0670a40a199a7a76179358c3f677e47e8951ca\n","  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n","Successfully built kss emoji\n","Installing collected packages: emoji, kss\n","Successfully installed emoji-1.7.0 kss-3.4.2\n"]},{"output_type":"stream","name":"stderr","text":["[Korean Sentence Splitter]: Initializing Pynori...\n"]},{"output_type":"stream","name":"stdout","text":["한국어 문장 토큰화 : ['딥 러닝 자연어 처리가 재미있기는 합니다.', '그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다.', '이제 해보면 알걸요?']\n"]}]},{"cell_type":"markdown","source":["# **한국어에서의 토큰화의 어려움**"],"metadata":{"id":"IzeeHD3HYmCD"}},{"cell_type":"markdown","source":["1. 교착어의 특성\n","    - 교착어란 조사, 어미 등을 붙여서 말을 만드는 언어를 말한다.\n","    - 띄어쓰기 단위가 영어처럼 독립적인 단어라면 띄어쓰기 단위로 토큰화를 하면된다.\n","    - 하지만 한국어는 어절이 독립적인 단어로 구성되는 것이 아니라 조사 등의 무언가가 붙어있는 경우가 많아서 이를 전부 분리해줘야 한다.\n","    - 자립 형태소 : 접사, 어미, 조사와 상관없이 자립하여 사용할 수 있는 형태소\n","    - 의존 형태소 : 다른 형태소와 결합하여 사용되는 형태소\n","    - 예) 문장 : 에디가 책을 읽었다. / 자립 형태소 : 에디, 책 / 의존 형태소 : -가, -을, 읽-, -었, -다\n","2. 한국어는 띄어쓰기가 영어보다 잘 지켜지지 않음\n","    - 한국어의 경우 띄어쓰기가 지켜지지 않아도 글을 쉽게 이해할 수 있는 언어이다."],"metadata":{"id":"LFG2QNHaYg0o"}},{"cell_type":"markdown","source":["### **품사 태깅(Part-of-speech tagging)**\n","- 단어의 의미를 제대로 파악하기 위해서는 해당 단어가 어떤 품사로 쓰였는지 보는 것이 주요 지표가 될 수 있다.\n","- 단어 토큰화 과정에서 각 단어가 어떤 품사로 쓰였는지를 구분해놓기도 하는데, 이 작업을 품사 태깅이라고 한다."],"metadata":{"id":"s0PX9ruQZsgZ"}},{"cell_type":"markdown","source":["NLTK에서는 Peen Treebank POS Tags라는 기준을 사용하여 품사를 태깅한다."],"metadata":{"id":"A-4qSS5_Z_tH"}},{"cell_type":"code","source":["import nltk\n","nltk.download('averaged_perceptron_tagger')\n","from nltk.tag import pos_tag\n","\n","text = \"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n","tokenized_sentence = word_tokenize(text)\n","\n","print('단어 토큰화 :',tokenized_sentence)\n","print('품사 태깅 :',pos_tag(tokenized_sentence))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"um5QH49rZ-NH","executionInfo":{"status":"ok","timestamp":1652864690424,"user_tz":-540,"elapsed":8432,"user":{"displayName":"남희정","userId":"05541235909914296292"}},"outputId":"17f6b523-fe57-418d-b1fc-64457e019d37"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","단어 토큰화 : ['I', 'am', 'actively', 'looking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n","품사 태깅 : [('I', 'PRP'), ('am', 'VBP'), ('actively', 'RB'), ('looking', 'VBG'), ('for', 'IN'), ('Ph.D.', 'NNP'), ('students', 'NNS'), ('.', '.'), ('and', 'CC'), ('you', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('Ph.D.', 'NNP'), ('student', 'NN'), ('.', '.')]\n"]}]},{"cell_type":"markdown","source":[" Penn Treebank POG Tags에서 PRP는 인칭 대명사, VBP는 동사, RB는 부사, VBG는 현재부사, IN은 전치사, NNP는 고유 명사, NNS는 복수형 명사, CC는 접속사, DT는 관사를 의미"],"metadata":{"id":"_shDgcIIac_4"}},{"cell_type":"markdown","source":["한국어 자연어 처리를 위해서는 KoNLPy라는 파이썬 패키지를 사용  \n","KoNLPy를 통해서 사용할 수 있는 형태소 분석기로 Okt(Open Korea Text), 메캅(Mecab), 코모란(Komoran), 한나눔(Hannanum), 꼬꼬마(Kkma)가 있다."],"metadata":{"id":"0Si7C9wiagvf"}},{"cell_type":"code","source":["!pip install konlpy\n","from konlpy.tag import Okt\n","\n","okt = Okt()\n","\n","print('OKT 형태소 분석 :',okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n","print('OKT 품사 태깅 :',okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n","print('OKT 명사 추출 :',okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\")) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xP7BvM-MaYS4","executionInfo":{"status":"ok","timestamp":1652864860073,"user_tz":-540,"elapsed":33697,"user":{"displayName":"남희정","userId":"05541235909914296292"}},"outputId":"4412c6fa-8394-473c-df4a-26e52d8fcfb7"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 4.5 MB/s \n","\u001b[?25hCollecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 53.7 MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.3.0 konlpy-0.6.0\n","OKT 형태소 분석 : ['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n","OKT 품사 태깅 : [('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n","OKT 명사 추출 : ['코딩', '당신', '연휴', '여행']\n"]}]},{"cell_type":"markdown","source":["Okt 메소드  \n","morphs : 형태소 추출  \n","pos : 품사 태깅\n","nouns : 명사 추출"],"metadata":{"id":"VDuXl-nTa-JB"}},{"cell_type":"code","source":["from konlpy.tag import Kkma\n","\n","kkma = Kkma()\n","\n","print('꼬꼬마 형태소 분석 :',kkma.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n","print('꼬꼬마 품사 태깅 :',kkma.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n","print('꼬꼬마 명사 추출 :',kkma.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-XjHHcxiazvg","executionInfo":{"status":"ok","timestamp":1652864933912,"user_tz":-540,"elapsed":22030,"user":{"displayName":"남희정","userId":"05541235909914296292"}},"outputId":"52f8580c-4068-4cb5-f887-3b1abc8776b8"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["꼬꼬마 형태소 분석 : ['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가보', '아요']\n","꼬꼬마 품사 태깅 : [('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('당신', 'NP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가보', 'VV'), ('아요', 'EFN')]\n","꼬꼬마 명사 추출 : ['코딩', '당신', '연휴', '여행']\n"]}]},{"cell_type":"markdown","source":["각 형태소 분석기는 성능과 결과가 다르게 나오기 때문에 형태소 분석기의 선택은 사용하고자 하는 필요 용도에 어떤 형태소 분석기가 가장 적절한지를 판단하고 사용한다."],"metadata":{"id":"qbeWprShbQcX"}}]}