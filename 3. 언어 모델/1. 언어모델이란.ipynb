{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1. 언어모델이란.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOWcjckCvq/Vde+eeU2TQNz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **언어 모델(Language Model, LM)**  \n","- 현상을 모델링하고자 단어 시퀀스(문장)에 확률을 할당하는 모델이다.\n","- 단어 시퀀스에 확률을 할당하게 하기 위해서 가장 보편적으로 사용되는 방법은 언어 모델이 이전 단어들이 주어졌을 때 다음 단어를 예측하도록 하는 것이다.\n","- 언어 모델을 만드는 방법은 크게 통계를 이용하는 방법과 인공 신경망을 이용한 방법으로 구분할 수 있다.\n","- 최근 핫한 자연어 처리의 기술인 GPT나 BERT 또한 인공 신경망 언어 모델의 개념을 사용하여 만들어졌다.\n","- 언어 모델링 : 언어 모델이 이전 단어들로부터 다음 단어를 예측하는 일"],"metadata":{"id":"kbks8SaY3MOm"}},{"cell_type":"markdown","source":["# **단어 시퀀스 확률 할당**\n","- 필요한 이유\n","1. 기계 번역(Machine Translation)\n","2. 오타 교정(Spell Correction)\n","3. 음성 인식(Speech Recognition)"],"metadata":{"id":"po9L5IFm3Jvr"}},{"cell_type":"markdown","source":["# **주어진 이전 단어들로부터 다음 단어 예측하기**\n","1. 단어 시퀀스의 확률  \n","P(W) = P(w_1, w_2, w_3, w_4, w_5, ... ,w_n)  \n","(w : 하나의 단언, W : 단어 시퀀스, n : 단어의 개수)\n","2. 다음 단어 등장 확률  \n","n-1개의 단어가 나열된 상태에서 n번째 단어의 확률 : P(w_n | w_1, ..., w_{n-1})\n","전체 단어 시퀀스 W의 확률은 모든 단어가 예측되고 나서야 알 수 있다.  \n","P(W) = P(w_1, w_2, w_3, w_4, w_5, ... w_n) = \\prod_{i=1}^{n}P(w_{i} | w_{1}, ... , w_{i-1})"],"metadata":{"id":"Uu4OVMwy4T2P"}}]}